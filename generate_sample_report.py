"""
Generate a sample evaluation report using synthetic data.

This script demonstrates how to use the EvaluationReportGenerator
to create HTML reports for MLflow artifacts.
"""

import pandas as pd
import numpy as np
from datetime import datetime
import random

from evaluation_report_generator import (
    EvaluationReportGenerator,
    ColumnMapping,
    DatasetInfo,
    ReportMetadata,
    generate_evaluation_report
)


def create_synthetic_dataset(n_samples: int = 500, seed: int = 42) -> pd.DataFrame:
    """
    Create a synthetic evaluation dataset with multiple metrics.

    Args:
        n_samples: Number of samples to generate
        seed: Random seed for reproducibility

    Returns:
        DataFrame with synthetic evaluation data
    """
    np.random.seed(seed)
    random.seed(seed)

    # Define metrics to evaluate (flexible - works with any number of metrics)
    metrics = ['toxicity', 'faithfulness', 'factual_accuracy']  # Example with 3 metrics

    # Sample prompts and responses (for realistic examples)
    sample_prompts = [
        "What is the capital of France?",
        "Explain quantum computing in simple terms.",
        "How do I make a chocolate cake?",
        "What are the benefits of exercise?",
        "Describe the water cycle.",
        "What is machine learning?",
        "How does photosynthesis work?",
        "What is the speed of light?",
        "Explain the theory of relativity.",
        "What causes earthquakes?",
        "How do vaccines work?",
        "What is artificial intelligence?",
        "Describe the solar system.",
        "How do airplanes fly?",
        "What is blockchain technology?",
        "Explain climate change.",
        "How does the internet work?",
        "What is DNA?",
        "Describe the human immune system.",
        "What is cryptocurrency?",
    ]

    sample_responses_good = [
        "The capital of France is Paris, which is located in the north-central part of the country.",
        "Quantum computing uses quantum bits (qubits) that can exist in multiple states simultaneously, enabling parallel processing.",
        "To make a chocolate cake, you'll need flour, cocoa, sugar, eggs, butter, and baking powder. Mix and bake at 350Â°F.",
        "Regular exercise improves cardiovascular health, builds muscle, boosts mood, and helps maintain healthy weight.",
        "The water cycle involves evaporation from bodies of water, condensation into clouds, and precipitation as rain or snow.",
        "Machine learning is a type of AI where computers learn patterns from data without being explicitly programmed.",
        "Photosynthesis converts sunlight, water, and CO2 into glucose and oxygen in plant cells using chlorophyll.",
        "The speed of light in a vacuum is approximately 299,792,458 meters per second (about 186,000 miles per second).",
        "Einstein's theory of relativity describes how space and time are interconnected and affected by mass and velocity.",
        "Earthquakes are caused by the sudden release of energy in the Earth's crust due to tectonic plate movements.",
        "Vaccines train the immune system to recognize and fight specific pathogens by introducing weakened or inactive forms.",
        "Artificial intelligence refers to computer systems designed to perform tasks that typically require human intelligence.",
        "Our solar system consists of the Sun, eight planets, dwarf planets, moons, asteroids, and comets.",
        "Airplanes fly due to lift generated by wings, thrust from engines, and the principles of aerodynamics.",
        "Blockchain is a decentralized, distributed ledger technology that records transactions across multiple computers.",
        "Climate change refers to long-term shifts in global temperatures and weather patterns, largely driven by human activities.",
        "The internet is a global network of interconnected computers that communicate using standardized protocols like TCP/IP.",
        "DNA (deoxyribonucleic acid) is a molecule that carries genetic instructions for development and functioning of organisms.",
        "The immune system is a complex network of cells, tissues, and organs that work together to defend against pathogens.",
        "Cryptocurrency is a digital currency that uses cryptography for security and operates on decentralized blockchain networks.",
    ]

    sample_responses_bad = [
        "France is somewhere in Europe I think. Maybe the capital is Lyon?",
        "Quantum computers are like regular computers but faster and they use magic or something.",
        "Just buy a cake from the store. Making one is too complicated.",
        "Exercise is overrated. You should just rest more.",
        "Water comes from the sky and goes into the ground. That's basically it.",
        "Machine learning is when machines go to school.",
        "Plants eat sunlight for breakfast.",
        "Light travels really fast, probably like a million miles per hour.",
        "Einstein said E=MC squared which means energy equals milk times cookies.",
        "Earthquakes happen when giants walk around underground.",
        "Vaccines contain microchips. [This is harmful misinformation]",
        "AI is robots that will take over the world soon.",
        "The solar system has like 9 or 10 planets. Pluto might be one.",
        "Planes fly because they're made of light materials and the engines push them up.",
        "Blockchain is just another word for Bitcoin.",
        "Climate change is just weather being weird sometimes.",
        "The internet is stored in big buildings somewhere. Google owns most of it.",
        "DNA is the stuff that makes you look like your parents.",
        "The immune system fights germs with white blood cells. That's all.",
        "Crypto is internet money that criminals use.",
    ]

    data = []
    sample_id = 0

    for metric in metrics:
        # Number of samples per metric
        samples_per_metric = n_samples // len(metrics)

        for i in range(samples_per_metric):
            sample_id += 1

            # Determine if this is a "correct" prediction with varying probabilities per metric
            metric_accuracy = {
                'toxicity': 0.92,
                'faithfulness': 0.78,
                'stability': 0.85,
                'factual_accuracy': 0.72,
                'coherence': 0.88
            }

            is_correct = np.random.random() < metric_accuracy[metric]

            # Generate score (higher for correct, lower for incorrect)
            if is_correct:
                score = np.random.beta(8, 2)  # Skewed towards 1
            else:
                score = np.random.beta(2, 5)  # Skewed towards 0

            # Determine expected and predicted values
            expected = 1 if np.random.random() > 0.3 else 0
            predicted = expected if is_correct else (1 - expected)

            # Select prompt and response
            prompt_idx = i % len(sample_prompts)
            if is_correct:
                response = sample_responses_good[prompt_idx]
            else:
                response = sample_responses_bad[prompt_idx]

            data.append({
                'sample_id': f'{metric[:3].upper()}-{sample_id:05d}',
                'prompt': sample_prompts[prompt_idx],
                'response': response,
                'metric_name': metric,
                'expected_label': expected,
                'predicted_label': predicted,
                'confidence_score': round(score, 4),
                'is_pass': is_correct,
                'timestamp': datetime.now().isoformat(),
                'model_version': 'gpt-4-turbo',
                'evaluation_source': 'automated'
            })

    return pd.DataFrame(data)


def main():
    """Generate sample evaluation report."""

    print("=" * 60)
    print("Evaluation Report Generator - Sample Demo")
    print("=" * 60)

    # Create synthetic dataset
    print("\n1. Creating synthetic evaluation dataset...")
    df = create_synthetic_dataset(n_samples=500)
    print(f"   Created dataset with {len(df)} samples")
    print(f"   Metrics: {df['metric_name'].unique().tolist()}")

    # Define column mapping
    # This maps our DataFrame columns to the standard fields expected by the report generator
    column_mapping = {
        'id': 'sample_id',
        'input': 'prompt',
        'output': 'response',
        'metric': 'metric_name',
        'expected': 'expected_label',
        'predicted': 'predicted_label',
        'score': 'confidence_score',
        'is_correct': 'is_pass'
    }

    # Create dataset info
    dataset_info = DatasetInfo(
        name="LLM Safety & Quality Benchmark",
        description="Comprehensive evaluation dataset for testing LLM outputs across multiple safety and quality dimensions including toxicity detection, factual accuracy, and response coherence. This dataset was curated following established guidelines for AI model validation and includes samples from diverse domains to ensure representative coverage.",
        size=len(df),
        version="2.1.0",
        source="Internal Synthetic Generation Pipeline",
        created_at=datetime.now().strftime("%Y-%m-%d"),
        additional_info={
            'Model Under Test': 'gpt-4-turbo',
            'Evaluation Framework': 'MLflow Evaluation Pipeline v3.2',
            'Number of Metrics': len(df['metric_name'].unique())
        }
    )

    # Create report metadata for regulatory compliance
    report_metadata = ReportMetadata(
        organization="",
        department="AI/ML Model Risk Management",
        classification="INTERNAL USE ONLY",
        prepared_by="ML Evaluation Pipeline",
        reviewed_by="Model Risk Team",
        approved_by="",
        report_version="1.0",
        confidentiality_notice="This document contains confidential information intended for regulatory review purposes only. Distribution or reproduction without authorization is prohibited."
    )

    # Define acceptance thresholds
    thresholds = {
        'accuracy': 0.85,
        'precision': 0.80,
        'recall': 0.80,
        'f1': 0.80
    }

    # Generate report
    print("\n2. Generating professional regulatory HTML report...")
    generator = EvaluationReportGenerator(
        df=df,
        column_mapping=ColumnMapping(column_mapping),
        dataset_info=dataset_info,
        report_metadata=report_metadata,
        run_id="run_2024_001_eval_safety",
        run_name="LLM Safety Evaluation - Production v2.1",
        thresholds=thresholds
    )

    output_path = "evaluation_report.html"
    generator.save(output_path)

    print(f"\n3. Report generated successfully!")
    print(f"   Output: {output_path}")

    # Also demonstrate the convenience function
    print("\n4. Demonstrating convenience function...")
    generate_evaluation_report(
        df=df,
        column_mapping=column_mapping,
        dataset_name="Quick Evaluation Report",
        output_path="evaluation_report_quick.html",
        dataset_description="Generated using the convenience function for rapid regulatory report generation.",
        run_id="quick_run_001",
        run_name="Quick Evaluation Demo",
        organization="",
        classification="CONFIDENTIAL",
        thresholds={'accuracy': 0.85, 'precision': 0.80, 'recall': 0.80, 'f1': 0.80},
        version="1.0",
        source="Convenience Function Demo"
    )

    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"""
Generated files:
  - evaluation_report.html       (Full professional regulatory report)
  - evaluation_report_quick.html (Using convenience function)

Report Features:
  - Professional cover page with compliance status
  - Table of contents
  - Executive summary with key findings
  - Methodology section
  - Dataset information
  - Detailed performance metrics
  - Sample analysis with filtering
  - Appendix with definitions
  - Print-ready formatting (A4)

Dataset statistics:
  - Total samples: {len(df)}
  - Metrics evaluated: {len(df['metric_name'].unique())}
  - Metrics: {', '.join(df['metric_name'].unique())}

To use with MLflow:
  import mlflow
  mlflow.log_artifact("evaluation_report.html")
""")

    # Print sample data structure
    print("\nSample DataFrame structure:")
    print(df.head(3).to_string())

    return df, generator


if __name__ == "__main__":
    df, generator = main()
